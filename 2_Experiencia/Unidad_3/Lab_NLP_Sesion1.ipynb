{"cells":[{"cell_type":"markdown","metadata":{"id":"UJh1pDdVwzTk"},"source":["# üß™ NLP Fundamentos + NLTK\n","**Talento TECH ‚Äî Nivel Innovador**\n","\n","\n","**Objetivo general:** que los campistas entiendan qu√© es NLP, el pipeline b√°sico de texto y construyan un mini-clasificador de sentimientos con NLTK.\n","\n"],"id":"UJh1pDdVwzTk"},{"cell_type":"markdown","metadata":{"id":"7LUXG1uDwzTt"},"source":["## üìã Agenda\n","1) ¬øQu√© es NLP y aplicaciones (10 min)\n","2) Pipeline b√°sico: tokenizaci√≥n ‚Üí normalizaci√≥n ‚Üí stopwords ‚Üí stemming vs lematizaci√≥n (25 min)\n","3) POS tagging y una mirada a parsing (10 min)\n","4) Representaciones: Bolsa de Palabras (BoW) y n-gramas (10 min)\n","5) **Hands-on**: Mini-clasificador Naive Bayes con NLTK (50 min)\n","6) Mini-reto en equipos y salida (15 min)\n"],"id":"7LUXG1uDwzTt"},{"cell_type":"markdown","metadata":{"id":"Vwz7PZDXwzTv"},"source":["## üöÄ Preparaci√≥n del entorno\n","- Si usas **Google Colab**, ejecuta la celda de instalaci√≥n.  \n","- Si usas local/Jupyter, aseg√∫rate de tener `nltk` instalado.\n"],"id":"Vwz7PZDXwzTv"},{"cell_type":"code","execution_count":1,"metadata":{"id":"instalacion","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757786465446,"user_tz":300,"elapsed":13913,"user":{"displayName":"Holguer Andrade Benadives","userId":"18368792823462611629"}},"outputId":"8ad68647-7492-4a3a-dcfb-16106e3dae0d"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["# Ejecuta esta celda en Colab\n","!pip -q install nltk scikit-learn\n","\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('omw-1.4')\n","nltk.download('punkt_tab')\n","nltk.download('averaged_perceptron_tagger_eng')"],"id":"instalacion"},{"cell_type":"markdown","metadata":{"id":"qQy7lTitwzTz"},"source":["## 1) üß† ¬øQu√© es NLP y para qu√© sirve?\n","Procesamiento del Lenguaje Natural (NLP) = que las m√°quinas entiendan y generen lenguaje humano.\n","\n","**Ejemplos cotidianos:**\n","- Buscadores y autocompletar.\n","- Chatbots y asistentes (servicio al cliente, FAQ).\n","- An√°lisis de sentimiento en rese√±as.\n","- Traducci√≥n autom√°tica y resumen de textos.\n","\n","**Actividad r√°pida (2 min):** Escribe 3 apps que uses que tengan NLP y qu√© tarea hacen.\n"],"id":"qQy7lTitwzTz"},{"cell_type":"markdown","metadata":{"id":"rt33B0MjwzT0"},"source":["## 2) üß™ Pipeline de texto\n","### 2.1 Tokenizaci√≥n\n","Dividir el texto en **tokens** (palabras, signos)."],"id":"rt33B0MjwzT0"},{"cell_type":"code","execution_count":2,"metadata":{"id":"tokenizacion","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757786655910,"user_tz":300,"elapsed":226,"user":{"displayName":"Holguer Andrade Benadives","userId":"18368792823462611629"}},"outputId":"11558939-ae5f-449b-cf93-d56aca681c38"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['¬°Hola',\n"," '!',\n"," 'Estoy',\n"," 'aprendiendo',\n"," 'NLP',\n"," 'con',\n"," 'Talento',\n"," 'Tech',\n"," '.',\n"," '¬øQu√©',\n"," 'tal',\n"," 'vamos',\n"," '?']"]},"metadata":{},"execution_count":2}],"source":["from nltk.tokenize import word_tokenize\n","\n","texto = \"¬°Hola! Estoy aprendiendo NLP con Talento Tech. ¬øQu√© tal vamos?\"\n","tokens = word_tokenize(texto)\n","tokens"],"id":"tokenizacion"},{"cell_type":"markdown","metadata":{"id":"UxVlqc18wzT2"},"source":["### 2.2 Normalizaci√≥n\n","- **lowercase** (min√∫sculas)\n","- quitar s√≠mbolos no alfab√©ticos\n","- (opcional) quitar acentos, emojis, etc."],"id":"UxVlqc18wzT2"},{"cell_type":"code","execution_count":3,"metadata":{"id":"normalizacion","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757786713779,"user_tz":300,"elapsed":5,"user":{"displayName":"Holguer Andrade Benadives","userId":"18368792823462611629"}},"outputId":"2a9a419a-2c52-4806-9f1a-1fbdb2b23b70"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['estoy', 'aprendiendo', 'nlp', 'con', 'talento', 'tech', 'tal', 'vamos']"]},"metadata":{},"execution_count":3}],"source":["import unicodedata\n","\n","def normalizar(tokens):\n","    norm = []\n","    for t in tokens:\n","        t2 = t.lower()\n","        # quitar tildes/acentos\n","        t2 = ''.join(c for c in unicodedata.normalize('NFD', t2) if unicodedata.category(c) != 'Mn')\n","        # solo letras\n","        if t2.isalpha():\n","            norm.append(t2)\n","    return norm\n","\n","tokens_norm = normalizar(tokens)\n","tokens_norm"],"id":"normalizacion"},{"cell_type":"markdown","metadata":{"id":"F9CtDDhZwzT3"},"source":["### 2.3 Stopwords (palabras vac√≠as)\n","Palabras muy frecuentes que suelen aportar poco significado (\"de\", \"la\", \"y\")."],"id":"F9CtDDhZwzT3"},{"cell_type":"code","execution_count":4,"metadata":{"id":"stopwords","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757786750553,"user_tz":300,"elapsed":19,"user":{"displayName":"Holguer Andrade Benadives","userId":"18368792823462611629"}},"outputId":"6c36310b-7f08-41ba-f90f-3135e1775751"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['aprendiendo', 'nlp', 'talento', 'tech', 'tal', 'vamos']"]},"metadata":{},"execution_count":4}],"source":["from nltk.corpus import stopwords\n","stop_es = set(stopwords.words('spanish'))\n","\n","[t for t in tokens_norm if t not in stop_es]"],"id":"stopwords"},{"cell_type":"markdown","metadata":{"id":"Fa42g57gwzT5"},"source":["### 2.4 Stemming vs Lemmatization\n","- **Stemming**: recorta palabras a su ‚Äúra√≠z‚Äù de forma heur√≠stica (puede producir formas no reales).\n","- **Lematizaci√≥n**: reduce a la forma can√≥nica (lemma). En NLTK est√° pensada para ingl√©s con WordNet."],"id":"Fa42g57gwzT5"},{"cell_type":"code","execution_count":5,"metadata":{"id":"stem-lemma","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757786799976,"user_tz":300,"elapsed":3111,"user":{"displayName":"Holguer Andrade Benadives","userId":"18368792823462611629"}},"outputId":"2a29c206-07f8-4a67-a1b4-f19e00307d23"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('studies', 'studi', 'study'),\n"," ('studying', 'studi', 'studying'),\n"," ('studied', 'studi', 'studied'),\n"," ('better', 'better', 'better'),\n"," ('cars', 'car', 'car')]"]},"metadata":{},"execution_count":5}],"source":["from nltk.stem import PorterStemmer, WordNetLemmatizer\n","\n","palabras_en = [\"studies\", \"studying\", \"studied\", \"better\", \"cars\"]\n","stemmer = PorterStemmer()\n","lemmatizer = WordNetLemmatizer()\n","\n","stems = [stemmer.stem(w) for w in palabras_en]\n","lemmas = [lemmatizer.lemmatize(w) for w in palabras_en]\n","\n","list(zip(palabras_en, stems, lemmas))"],"id":"stem-lemma"},{"cell_type":"markdown","metadata":{"id":"XJNDQv_GwzT5"},"source":["## 3) üß∑ POS Tagging (etiquetado gramatical)\n","Asignar categor√≠as gramaticales (sustantivo, verbo, adjetivo, etc.) a cada token.\n","\n","> Nota: El etiquetador por defecto de NLTK est√° entrenado en ingl√©s."],"id":"XJNDQv_GwzT5"},{"cell_type":"code","execution_count":6,"metadata":{"id":"pos","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757786829111,"user_tz":300,"elapsed":161,"user":{"displayName":"Holguer Andrade Benadives","userId":"18368792823462611629"}},"outputId":"77af5a13-f3d8-44a7-d692-071034e26869"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('The', 'DT'),\n"," ('amazing', 'JJ'),\n"," ('movie', 'NN'),\n"," ('had', 'VBD'),\n"," ('a', 'DT'),\n"," ('weak', 'JJ'),\n"," ('story', 'NN'),\n"," ('but', 'CC'),\n"," ('great', 'JJ'),\n"," ('acting', 'NN')]"]},"metadata":{},"execution_count":6}],"source":["from nltk import pos_tag\n","from nltk.tokenize import word_tokenize\n","\n","oracion_en = word_tokenize(\"The amazing movie had a weak story but great acting\")\n","pos_tag(oracion_en)"],"id":"pos"},{"cell_type":"markdown","metadata":{"id":"0db7b4a8"},"source":["**Abreviaturas comunes en POS Tagging (NLTK/Penn Treebank Tagset):**\n","\n","*   **JJ**: Adjetivo (ej. \"amazing\", \"weak\", \"great\")\n","*   **NN**: Sustantivo, singular (ej. \"movie\", \"story\", \"acting\")\n","*   **NNS**: Sustantivo, plural\n","*   **VB**: Verbo, forma base\n","*   **VBD**: Verbo, pasado (ej. \"had\")\n","*   **DT**: Determinante (ej. \"The\", \"a\")\n","*   **IN**: Preposici√≥n o conjunci√≥n subordinada\n","*   **CC**: Conjunci√≥n coordinante (ej. \"but\")\n","\n","Puedes encontrar una lista m√°s completa buscando \"Penn Treebank Tagset\"."],"id":"0db7b4a8"},{"cell_type":"markdown","metadata":{"id":"Ial1Y95lwzT6"},"source":["## 4) üß∞ Representaciones: BoW y n-gramas\n","- **BoW (Bolsa de Palabras)**: cuenta ocurrencias, ignora orden.\n","- **n-gramas**: secuencias de n palabras (bi-gramas, tri-gramas)."],"id":"Ial1Y95lwzT6"},{"cell_type":"code","execution_count":8,"metadata":{"id":"bow","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757786927104,"user_tz":300,"elapsed":18,"user":{"displayName":"Holguer Andrade Benadives","userId":"18368792823462611629"}},"outputId":"5d29c2a0-ed80-4fa5-a63b-b1b8e1e32ca8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('buena', 3), ('pelicula', 1), ('final', 1), ('malo', 1)]"]},"metadata":{},"execution_count":8}],"source":["from nltk.probability import FreqDist\n","from nltk.corpus import stopwords\n","\n","stop_es = set(stopwords.words('spanish'))\n","\n","tokens_demo_espanol = normalizar(word_tokenize(\"Esta pel√≠cula es buena, buena, buena, pero el final es malo\"))\n","fd_espanol = FreqDist([t for t in tokens_demo_espanol if t not in stop_es])\n","fd_espanol.most_common(10)"],"id":"bow"},{"cell_type":"code","execution_count":9,"metadata":{"id":"ngrams","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757786942400,"user_tz":300,"elapsed":8,"user":{"displayName":"Holguer Andrade Benadives","userId":"18368792823462611629"}},"outputId":"52abe0e9-dce4-406f-8725-f7bba512cbd3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["([('pelicula', 'buena'),\n","  ('buena', 'buena'),\n","  ('buena', 'buena'),\n","  ('buena', 'final'),\n","  ('final', 'malo')],\n"," [('pelicula', 'buena', 'buena'),\n","  ('buena', 'buena', 'buena'),\n","  ('buena', 'buena', 'final'),\n","  ('buena', 'final', 'malo')])"]},"metadata":{},"execution_count":9}],"source":["from nltk.util import ngrams\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","\n","stop_es = set(stopwords.words('spanish'))\n","\n","tokens_demo_espanol = normalizar(word_tokenize(\"Esta pel√≠cula es buena, buena, buena, pero el final es malo\"))\n","# Remove stopwords before generating ngrams for more meaningful phrases\n","tokens_filtered = [t for t in tokens_demo_espanol if t not in stop_es]\n","\n","bigrams_espanol = list(ngrams(tokens_filtered, 2))\n","trigrams_espanol = list(ngrams(tokens_filtered, 3))\n","bigrams_espanol[:10], trigrams_espanol[:10]"],"id":"ngrams"},{"cell_type":"markdown","metadata":{"id":"3Kkk5RGywzT7"},"source":["## 5) ü§ñ Mini-proyecto: Clasificador de Sentimientos (Naive Bayes + NLTK)\n","Entrenaremos un clasificador simple usando un dataset peque√±o de ejemplo. **Recomendado en ingl√©s** para aprovechar lematizaci√≥n y POS por defecto. Luego puedes cambiar/mezclar con textos en espa√±ol (quitar lematizaci√≥n o usar solo stopwords).\n"],"id":"3Kkk5RGywzT7"},{"cell_type":"code","execution_count":10,"metadata":{"id":"dataset-mini","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757787034181,"user_tz":300,"elapsed":47,"user":{"displayName":"Holguer Andrade Benadives","userId":"18368792823462611629"}},"outputId":"7e520c42-9bdb-48c5-b040-5ee46d5b4f49"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8,\n"," [('i hated this movie', 'neg'),\n","  ('i loved the film', 'pos'),\n","  ('absolutely fantastic soundtrack', 'pos'),\n","  ('boring and predictable', 'neg')])"]},"metadata":{},"execution_count":10}],"source":["import random\n","\n","data = [\n","    (\"this movie is amazing\", \"pos\"),\n","    (\"i loved the film\", \"pos\"),\n","    (\"what a wonderful performance\", \"pos\"),\n","    (\"absolutely fantastic soundtrack\", \"pos\"),\n","    (\"what a terrible plot\", \"neg\"),\n","    (\"boring and predictable\", \"neg\"),\n","    (\"the acting was weak\", \"neg\"),\n","    (\"i hated this movie\", \"neg\"),\n","]\n","random.shuffle(data)\n","len(data), data[:4]"],"id":"dataset-mini"},{"cell_type":"markdown","metadata":{"id":"ysMYa6DzwzT8"},"source":["### 5.1 Preprocesamiento y extracci√≥n de features\n","Usaremos un **bols√≥n de tokens** (presencia/ausencia) tras normalizar y quitar stopwords."],"id":"ysMYa6DzwzT8"},{"cell_type":"code","execution_count":11,"metadata":{"id":"preproc-features","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757787420347,"user_tz":300,"elapsed":42,"user":{"displayName":"Holguer Andrade Benadives","userId":"18368792823462611629"}},"outputId":"4273205e-5f26-4a99-9646-adf1901c8796"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[({'hated': True, 'movie': True}, 'neg'),\n"," ({'loved': True, 'film': True}, 'pos')]"]},"metadata":{},"execution_count":11}],"source":["from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","\n","stop_en = set(stopwords.words(\"english\"))\n","lem = WordNetLemmatizer()\n","\n","def preprocess_en(text):\n","    toks = word_tokenize(text.lower())\n","    toks = [t for t in toks if t.isalpha() and t not in stop_en]\n","    toks = [lem.lemmatize(t) for t in toks]\n","    return {t: True for t in toks}\n","\n","featuresets = [(preprocess_en(t), y) for t,y in data]\n","featuresets[:2]"],"id":"preproc-features"},{"cell_type":"code","execution_count":12,"metadata":{"id":"train-test-split","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757787623938,"user_tz":300,"elapsed":41,"user":{"displayName":"Holguer Andrade Benadives","userId":"18368792823462611629"}},"outputId":"c6060a86-d3da-4310-a0e7-a9ecb77c6efa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6, 2)"]},"metadata":{},"execution_count":12}],"source":["split = int(0.8*len(featuresets))\n","train_set, test_set = featuresets[:split], featuresets[split:]\n","len(train_set), len(test_set)"],"id":"train-test-split"},{"cell_type":"code","execution_count":13,"metadata":{"id":"train-eval","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757787884671,"user_tz":300,"elapsed":38,"user":{"displayName":"Holguer Andrade Benadives","userId":"18368792823462611629"}},"outputId":"d01b07ac-0d1d-45d5-e19c-8632d86947b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.0\n","Most Informative Features\n","                  boring = None              pos : neg    =      1.8 : 1.0\n","                   hated = None              pos : neg    =      1.8 : 1.0\n","             predictable = None              pos : neg    =      1.8 : 1.0\n","                   movie = True              neg : pos    =      1.7 : 1.0\n","                   movie = None              pos : neg    =      1.4 : 1.0\n"]}],"source":["from nltk import NaiveBayesClassifier, classify\n","\n","clf = NaiveBayesClassifier.train(train_set)\n","acc = classify.accuracy(clf, test_set)\n","print(\"Accuracy:\", round(acc, 3))\n","clf.show_most_informative_features(5)"],"id":"train-eval"},{"cell_type":"markdown","metadata":{"id":"I2pGzRVmwzT-"},"source":["### 5.2 Probemos el modelo\n","Escribe una rese√±a y veamos si clasifica bien. Prueba frases positivas y negativas."],"id":"I2pGzRVmwzT-"},{"cell_type":"code","execution_count":null,"metadata":{"id":"predict-one"},"outputs":[],"source":["text = \"the actors were great but the story was weak\"\n","pred = clf.classify(preprocess_en(text))\n","print(text, \"=>\", pred)"],"id":"predict-one"},{"cell_type":"markdown","metadata":{"id":"PafE0dpKwzT-"},"source":["### 5.3 M√©tricas b√°sicas (opcional con scikit-learn)\n","Construimos `y_true` y `y_pred` para ver matriz de confusi√≥n y F1. *Requiere `scikit-learn`.*"],"id":"PafE0dpKwzT-"},{"cell_type":"code","execution_count":null,"metadata":{"id":"metrics"},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","\n","y_true = [y for _, y in test_set]\n","y_pred = [clf.classify(x) for x, _ in test_set]\n","print(confusion_matrix(y_true, y_pred))\n","print(classification_report(y_true, y_pred))"],"id":"metrics"},{"cell_type":"markdown","metadata":{"id":"_6OO8hT7wzT_"},"source":["## üß© Mini-reto (10‚Äì15 min)\n","1. En equipos, a√±adan **5 frases** nuevas (propias) al dataset y re-entrenen.\n","2. Modifiquen el **preprocesamiento**:\n","   - prueben **sin lematizaci√≥n**,\n","   - o eliminen menos **stopwords**,\n","   - o construyan **bi-gramas** como features.\n","3. Midan el impacto en `accuracy`.\n"],"id":"_6OO8hT7wzT_"},{"cell_type":"code","execution_count":null,"metadata":{"id":"reto-espacio"},"outputs":[],"source":["# === Espacio de trabajo del reto ===\n","# 1) Agrega aqu√≠ nuevas frases al dataset 'data' (texto, etiqueta)\n","data.extend([\n","    (\"i really enjoyed the story\", \"pos\"),\n","    (\"the movie was too long and dull\", \"neg\"),\n","])\n","\n","# 2) Cambia el preprocesamiento si quieres experimentar\n","def preprocess_variant(text):\n","    toks = word_tokenize(text.lower())\n","    toks = [t for t in toks if t.isalpha() and t not in stop_en]\n","    # ejemplo: sin lematizacion\n","    return {t: True for t in toks}\n","\n","featuresets = [(preprocess_variant(t), y) for t,y in data]\n","random.shuffle(featuresets)\n","split = int(0.8*len(featuresets))\n","train_set, test_set = featuresets[:split], featuresets[split:]\n","\n","clf = NaiveBayesClassifier.train(train_set)\n","from nltk import classify\n","acc = classify.accuracy(clf, test_set)\n","print(\"Accuracy variante:\", round(acc, 3))"],"id":"reto-espacio"},{"cell_type":"markdown","metadata":{"id":"qnhTKReNwzT_"},"source":["## üîå (Opcional) Cargar dataset propio (CSV)\n","Formato esperado: dos columnas `text,label` con etiquetas tipo `pos/neg` (o como prefieras)."],"id":"qnhTKReNwzT_"},{"cell_type":"code","execution_count":null,"metadata":{"id":"upload-csv"},"outputs":[],"source":["import pandas as pd\n","from io import StringIO\n","\n","# En Colab puedes usar: from google.colab import files; files.upload()\n","# Para demo, creamos un CSV en memoria:\n","csv_demo = \"\"\"text,label\\nI love this app,pos\\nThis service is awful,neg\\nGreat features and support,pos\\nNot worth the price,neg\\n\"\"\"\n","df = pd.read_csv(StringIO(csv_demo))\n","df.head()"],"id":"upload-csv"},{"cell_type":"code","execution_count":null,"metadata":{"id":"train-csv"},"outputs":[],"source":["# Entrenar con el CSV cargado\n","dataset = [(t, y) for t, y in zip(df[\"text\"].astype(str), df[\"label\"].astype(str))]\n","featuresets = [(preprocess_en(t), y) for t,y in dataset]\n","random.shuffle(featuresets)\n","split = int(0.8*len(featuresets))\n","train_set, test_set = featuresets[:split], featuresets[split:]\n","clf = NaiveBayesClassifier.train(train_set)\n","from nltk import classify\n","print(\"Accuracy con CSV:\", round(classify.accuracy(clf, test_set), 3))"],"id":"train-csv"},{"cell_type":"markdown","metadata":{"id":"SsWLNDuGwzUB"},"source":["## ‚úÖ Exit-ticket (3 preguntas r√°pidas)\n","1) ¬øQu√© problema resuelve la **tokenizaci√≥n**?  \n","2) ¬øEn qu√© se diferencian **stemming** y **lematizaci√≥n**?  \n","3) ¬øPor qu√© dividimos en **train/test**?\n","\n","‚Äî ¬°Nos vemos en la **Sesi√≥n 2** (tareas comunes de NLP + reto con dataset)!"],"id":"SsWLNDuGwzUB"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}